---
title: 朴素贝叶斯
date: 2020-02-13 22:57:42
categories: ML
tags:
    - Bayes Theorem
    - Machine Learning 

mathjax: true
---

# 朴素贝叶斯

## 参数估计
### 离散输入空间下MLE推导
> 百度 朴素贝叶斯 极大似然估计 推导
> 这个是李航书上的课后题

## Q & A
1. 朴素贝叶斯中为什么将 $P(X=x_j|Y=y_i)$ 视为“似然”？
> 似然是针对估计概率模型的参数说的，这里的概率模型就是 $X^{(i)}|Y$ 服从多类分布，待估计参数也就是每个类别的概率
> 计算完每个特征的似然后，我们在此基础上加入条件独立假设，得到总的似然
> 数据在这里一方面让我们获得先验该率 $P(Y)$ （其实这里我们也是假设Y服从多类分布，再用MLE），一方面给我们计算概率模型的参数提供数据


2. 为什么计算后验概率不直接将数据的频率作为概率?
> 1. 我们采用的是贝叶斯统计而不是频率统计，贝叶斯统计的核心是使用观测不断更新先验。
> 2. 如果我们采用频率也就是将后验视为一个条件概率来考虑，会出现以下问题
>     - 特征数很多、特征空间很大时，我们需要遍历所有特征空间上的点，计算每种情况上的频率作为 $P(Y=y_k|X=x_i)$ ，时间上不允许
>     - 当特征空间并非远大于样本空间时，由于样本数少，样本在特征空间上很稀疏，采用频率的方法会不准确

3. 朴素贝叶斯有什么优势?
> 1. 计算速度快，时间复杂度低
> 2. 方便引入新的特征


4. 参数估计时为什么是MLE而不是频率？
> 离散变量下，MLE和频率计算的结果相同，而我们说我们是用MLE求得的参数是因为大环境是贝叶斯统计，参数被视为随机变量而不是固定的值
> 只不过当我们做推断时，参数值需要确定，因此我们选择具有最大似然的参数值（实际上MLE是Frequentist的估计方法）

5. $P(Y = y_i)$ 和 $P(Y = c_k)$ 区别？
> 一个表示随机变量Y取特定值 $y_i$ 的概率，另一个表示随机变量取值和样本 $c_k$ 相同的概率

## 待学习
> 1. 贝叶斯估计 迪利克雷分布
> 2. MAP有什么意义？